Predicting exercise class using machine learning algorithms

Objective: To determine the type of exercise using measurements from various movement sensors.  Using a random forest model combined with 5-fold cross validation I am able to achieve greater than 99% accuracy detecting all five classes.

	Researchers attached accelerometers to subjects who were then asked to perform dumbbell exercises while in one of five classes: sitting-down, standing-up, standing, walking, and sitting.  The data along with these classes (labeled A through E) are what are found in the data sets provided for this project.  The data file contains 19622 observations 160 variables (including “classe”), however many of these are not meaningful to the analysis.  To shorten the runtime and remove some possible misclassification of the data I removed variables which showed near-zero variation (approx. 60 variables) as well as variables with mostly nonexistent data (i.e., more than ~80% NAs, approx. 45 variables) using the following code:

#####################################
### Removing near zero variance data
#####################################
## some variables have no variance.  Let's get rid of those now
nzv_data <- nearZeroVar(all_data, saveMetrics=TRUE)
good_data <- all_data[ , !nzv_data$nzv]

## I'll also remove the index column, "X"
good_data <- good_data[, -1] 
GD1 <- good_data

#########################################
### Removing variables with too many NAs
#########################################
## Some variables have > 19000 NAs. I'm going to eliminate these here
good_list <- c()
for(i in 1:dim(good_data)[2]){
        num_NA <- sum(is.na(good_data[ ,i]))
        if(num_NA < 18000){
                good_list <- c(good_list, i)
        }
}
good_data <- good_data[, good_list]


Additionally, I removed the timestamp, num_window, and username variables since they are not needed for the classification.  The remaining data frame contained 53 variables (including “classe”) that could be used to determine class.  I then split the data into typical training (70%) and testing (30%) sets using createDataPartition.  Next, I trained a random forest model using the caret package’s “train” function.  I introduced 5-fold cross-validation using the “trControl” function.  This model is computationally intensive and takes about 45 minutes to complete on my computer, however the results show high accuracy (99.06%).  Using varImpPlot in the randomForest package I show the variables that show the largest decrease in Gini in Figure 1:
 
Figure 1: Random Forest model variables ordered by greatest decrease in Gini.
	The two highest factors are plotted in Figure 2 along with the class as color to show the minimal separation between classes:
 
Figure 2: Pitch Forearm vs Roll Belt colored by “classe”.
I then checked the accuracy of this model against the remaining testing data.  A summary of the confusion matrix is shown below:
> print(confusionMatrix(pred, testing$classe))
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1674    2    0    0    0
         B    0 1136    4    0    0
         C    0    1 1020    6    1
         D    0    0    2  958    1
         E    0    0    0    0 1080

Overall Statistics
                                          
               Accuracy : 0.9971          
                 95% CI : (0.9954, 0.9983)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9963          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9974   0.9942   0.9938   0.9982
Specificity            0.9995   0.9992   0.9984   0.9994   1.0000
Pos Pred Value         0.9988   0.9965   0.9922   0.9969   1.0000
Neg Pred Value         1.0000   0.9994   0.9988   0.9988   0.9996
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2845   0.1930   0.1733   0.1628   0.1835
Detection Prevalence   0.2848   0.1937   0.1747   0.1633   0.1835
Balanced Accuracy      0.9998   0.9983   0.9963   0.9966   0.9991

The model exhibits >99% sensitivity and specificity for all classes with particularly high values for class E which is not surprising given its slightly greater degree of separation as seen in Fig. 2.  Finally, I predicted the test cases using the same procedure as described above.

> test_pred
 [1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E

This model has very high accuracy and I believe that I have successfully predicted the test cases.  Although the accuracy is already quite high, it may be possible to further improve the model by shortening the run time.  This can potentially be achieved by using PCA or some other preprocessing package which would allow for comparable accuracy using fewer variables.
